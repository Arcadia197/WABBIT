; -------------------------------------------------------------------------------------------------
[Blocks]
; size of the dense-image we generate before decomposing it into blocks
number_domain_nodes=513;

; size of each block, should be odd (17, 33, 65 etc)
number_block_nodes=33;

; ghost nodes for each block
number_ghost_nodes=4;

; maximum number of blocks (heavy data) per proc
number_blocks=256;

; number of datafields in heavy data array
number_data_fields=2;

; threshold value for thresholding wavelet coefficients
eps=1e-3;

; treelevel bounds
max_treelevel=5;
min_treelevel=1;

; switch for mesh adaption, 1=on, ...=off
adapt_mesh=1;

; block distribution for balancing (also used for start distribution)
; [equal | sfc1]
; equal -> simple uniformly distribution
; sfc1  -> space filling curve
block_dist=equal;

; -------------------------------------------------------------------------------------------------
[Time]
; calculated time
time_max=20.0;

; CFL criterium
CFL=0.5;

; write frequency for output, choose very large number for disabling output on disk
write_freq=20;

; -------------------------------------------------------------------------------------------------
[Physics]
; convection velocity, can be different for each data field (first two values correspond to data field 1, ...)
u0=1.0 0.0 -1.0 0.0;

; diffusion coefficient, can be different for each data field (first value correspond to data field 1, ...)
nu=1e-2 1e-4;

; domain size
Lx=100.0;
Ly=100.0;

; initial field (set additional parameters in according file in INI folder)
initial_cond=gauss_blob;

; -------------------------------------------------------------------------------------------------
[Discretization]
order_discretization=FD_4th_central_optimized ; [ FD_2nd_central | FD_4th_central_optimized ]

; order of refinement predictor
order_predictor=multiresolution_4th; [ multiresolution_4th | multiresolution_2nd ]

; boundary condition
boundary_cond=periodic; [ periodic ]